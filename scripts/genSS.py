__author__ = 'Jon Mallen'

import os
import sys
import shutil
import argparse
import pandas as pd
import numpy as np
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt
from binarize_data import binarize_data

# genSS.py assumes a BoolODE simulation in which the time is overrun, skewing each number of cells in discrete
# steady state(s) to be a larger value than each number of cells in discrete, non-steady states. States with a
# multiplicity over a certain threshold are called to be steady states and are written to a steady state file.

# Define arguments
parser = argparse.ArgumentParser("Scan simulated expression data for steady states.")
parser.add_argument('-f', '--pathToFiles', default='', type=str, help='Specify path to folder containing the '
                                                                      'ExpressionData.csv file generated by the BoolODE'
                                                                      ' simulation.')

# Parse arguments
args = parser.parse_args()
path = args.pathToFiles
inFile = path + "/ExpressionData.csv"
if not os.path.exists(inFile):
    sys.exit('Error: No ExpressionData.csv file is present in the specified path to files.')

# Read the data
DF = pd.read_csv(inFile, sep=',', index_col=0)
num_nodes = len(DF)
cell_list = DF.columns

# Binarize the data
binDF = binarize_data(DF)
num_cells = len(cell_list)

# Find unique states in data
uniques_df = pd.DataFrame()
num_uniques = 0
for i in cell_list:
    unique_found = True
    for j in uniques_df.columns:
        if uniques_df[j].equals(binDF[i]):
            unique_found = False
            break
    if unique_found:
        uniques_df[str(num_uniques)] = binDF[i]
        num_uniques += 1

# Find multiplicity of each state
state_multiplicities = [0] * num_uniques
for i in cell_list:
    for j in uniques_df.columns:
        if uniques_df[j].equals(binDF[i]):
            state_multiplicities[int(j)] += 1

# Sort states and their multiplicities by value
sort_multiplicities = sorted(state_multiplicities, reverse=True)
unique_multiplicities = list(np.unique(np.array(sort_multiplicities)))
unique_multiplicities.reverse()
sort_states = []
for k in unique_multiplicities:
    locs = [str(a) for a in np.where(np.array(state_multiplicities) == k)[0]]
    sort_states.extend(locs)

# Auto-predict which states correspond to steady-states using k-means clustering with custom corrections
if num_uniques > 20:
    uniques_range = range(20)
else:
    uniques_range = range(num_uniques)
multiplicity_coordinate_list = [[b, sort_multiplicities[b]] for b in uniques_range]
multiplicity_array = np.array(multiplicity_coordinate_list)
k_means = KMeans(n_clusters=2).fit(multiplicity_array)
k_means_centroid_average = sum(k_means.cluster_centers_[:, 1]) / 2
cluster_labels = k_means.labels_
cluster1 = []
cluster1_indices = []
cluster2 = []
cluster2_indices = []
for i in uniques_range:
    if cluster_labels[i] == 0:
        cluster1.append(sort_multiplicities[i])
        cluster1_indices.append(sort_states[i])
    else:
        cluster2.append(sort_multiplicities[i])
        cluster2_indices.append(sort_states[i])
cluster1_mean = sum(cluster1) / len(cluster1)
cluster2_mean = sum(cluster2) / len(cluster2)
predicted_steady_state_list = []
if cluster1_mean > cluster2_mean:
    upper_cluster = cluster1
    predicted_steady_state_list.extend(cluster1_indices)
    lower_cluster = cluster2
    lower_cluster_mean = cluster2_mean
    lower_cluster_indices = cluster2_indices
else:
    upper_cluster = cluster2
    predicted_steady_state_list.extend(cluster2_indices)
    lower_cluster = cluster1
    lower_cluster_mean = cluster1_mean
    lower_cluster_indices = cluster1_indices
lower_cluster_stdev = np.std(lower_cluster)
for a in range(len(lower_cluster)):
    ten_percent_weedout = .1 * min(upper_cluster)
    if lower_cluster[a] > lower_cluster_mean + lower_cluster_stdev and lower_cluster[a] > ten_percent_weedout:
        upper_cluster.append(lower_cluster[a])
        predicted_steady_state_list.append(lower_cluster_indices[a])
num_predicted_steady_states = len(predicted_steady_state_list)
predicted_right_most_index = predicted_steady_state_list[num_predicted_steady_states - 1]
print("The Greedy k-Means clustering algorithm predicts %d predominant states with a right-most index of %s."
      % (num_predicted_steady_states, predicted_right_most_index))


# Common method for preparing output files
def write_to_file(data_name, file_type, file_path, regulator):
    name = data_name.split('_df')[0]
    if file_type == 'tsv':
        eval(data_name).to_csv(name + '.' + file_type, sep="\t")
    elif file_type == 'csv':
        eval(data_name).to_csv(name + '.' + file_type, sep=',')
    if os.path.exists(file_path + '/' + name + '.' + file_type):
        os.remove(file_path + '/' + name + '.' + file_type)
    shutil.move(os.path.abspath(name + '.' + file_type), file_path)
    if regulator == 0:
        os.remove(file_path + '/' + name + '.' + file_type)


# Examine state multiplicities and judge number of positive outliers
f, ax = plt.subplots(figsize=(15, 5))
if num_uniques > 20:
    num_interest = 20
else:
    num_interest = num_uniques
ax.bar(sort_states[:num_interest], sort_multiplicities[:num_interest], color='tab:blue')
ax.set_xlabel('State Index', fontsize=15)
ax.set_ylabel('Multiplicity Value', fontsize=15)
plt.suptitle('Multiplicities of All States in Binarized Expression Data', fontsize=18)
ax.set_title('Please note the right-most index of all states with visibly larger multiplicities.', fontsize=12,
             fontweight='bold')
plt.savefig('StateMultiplicities.png')
write_to_file('StateMultiplicities', 'png', path, 1)
plt.show()

ask_for_state = False
steady_states_present = True
cyclic_behavior = False
while True:
    try:
        steady_state_prediction = input("Do you agree with the result of the Greedy k-Means clustering algorithm? "
                                        "(yes or no): ")
        if steady_state_prediction == 'yes' or steady_state_prediction == 'no':
            if steady_state_prediction == 'no':
                ask_for_state = True
            else:
                state_cutoff = predicted_right_most_index
            break
        else:
            print("Error: Only 'yes' or 'no' is a valid answer.")
    except ValueError:
        continue
if ask_for_state:
    while True:
        try:
            state_cutoff = input("Type the right-most index, or if unclear, type 'none': ")
            if state_cutoff == 'none':
                steady_states_present = False
                break
            elif not state_cutoff.isdigit():
                print("Error: Please specify only numerical values for the state index.")
            elif state_cutoff not in sort_states:
                print("Error: Specified state index does not exist within the list of state indices.")
            else:
                break
        except ValueError:
            continue
while True:
    try:
        cycle_evidence = input("Does visualizing the dimensional reduction of the expression data reveal any "
                               "dominating cyclic behavior? (yes or no): ")
        if cycle_evidence == 'yes' or cycle_evidence == 'no':
            if cycle_evidence == 'yes':
                steady_states_present = False
                cyclic_behavior = True
            break
        else:
            print("Error: Only 'yes' or 'no' is a valid answer.")
    except ValueError:
        continue


# Common method for organizing states to pandas dataframe
def get_states(make_df):
    state_list = []
    for m in sort_states:
        state_list.append(m)
        if m == state_cutoff:
            break
    num_states = len(state_list)
    states_df = pd.DataFrame(columns=uniques_df.index)
    for s in state_list:
        states_df.loc[len(states_df.index)] = list(uniques_df[s])
    if make_df:
        return states_df
    else:
        return num_states


# Call steady-states and majority states of dominating cycle
if steady_states_present:
    steady_states_df = get_states(True)
    num_steady_states = get_states(False)
else:
    steady_states_df = pd.DataFrame()
    num_steady_states = 0

if cyclic_behavior:
    cyclic_states_df = get_states(True)
    num_cyclic_states = get_states(False)
else:
    cyclic_states_df = pd.DataFrame()
    num_cyclic_states = 0

# Write steady states or predominating states of dominant cycle to file
write_to_file("steady_states_df", "tsv", path, num_steady_states)
print("Number of Called Steady States: " + str(num_steady_states))
if steady_states_present:
    print("The steady-states have been written to the steady_states.tsv file.")
write_to_file("cyclic_states_df", "tsv", path, num_cyclic_states)
if cyclic_behavior:
    print("The predominant states of the dominating cycle have been written to the cyclic_states.tsv file.")

# Re-perform k-Means clustering, if necessary

do_k_means = False
while True:
    try:
        to_do_k_means = input("Would you like to re-perform k-means clustering of the expression data? "
                              "(yes or no): ")
        if to_do_k_means == 'yes' or to_do_k_means == 'no':
            if to_do_k_means == 'yes':
                do_k_means = True
            break
        else:
            print("Error: Only 'yes' or 'no' is a valid answer.")
    except ValueError:
        continue
if do_k_means:
    if cyclic_behavior:
        num_clusters = 1
    else:
        num_clusters = num_steady_states
        choose_new_num_clusters = False
        while True:
            try:
                use_num_steady_states = input("There are %d called steady states. Would you like to use this value for "
                                              "the number of clusters? (yes or no): " % num_steady_states)
                if use_num_steady_states == 'yes' or use_num_steady_states == 'no':
                    if use_num_steady_states == 'no':
                        choose_new_num_clusters = True
                    break
                else:
                    print("Error: Only 'yes' or 'no' is a valid answer.")
            except ValueError:
                continue
        if choose_new_num_clusters:
            while True:
                try:
                    num_clusters = input("Type the desired number of clusters: ")
                    if not num_clusters.isdigit():
                        print("Error: Please specify a numerical value for the number of clusters.")
                    else:
                        break
                except ValueError:
                    continue
    if num_clusters == 1:
        print("Requested 1 cluster...not performing k-means clustering for 1 cluster.")
        clusterFile = path + '/ClusterIds.csv'
        if os.path.exists(clusterFile):
            print("Deleting the ClusterIds.csv file present.")
            os.remove(clusterFile)
    else:
        cluster_labels = KMeans(n_clusters=int(num_clusters)).fit(DF.T.values).labels_
        ClusterIds_df = pd.DataFrame(data=cluster_labels, index=DF.columns, columns=['cl'])
        write_to_file('ClusterIds_df', 'csv', path, 1)
        print("The new clusters have been written to the ClusterIds.csv file.")

    do_k_means_for_complementary_data = False
    while True:
        try:
            to_do_k_means_for_complementary_data = input("Would you like to re-perform clustering for the "
                                                         "complementary expression data of lower simulation time? "
                                                         "(yes or no): ")
            if to_do_k_means_for_complementary_data == 'yes' or to_do_k_means_for_complementary_data == 'no':
                if to_do_k_means_for_complementary_data == 'yes':
                    do_k_means_for_complementary_data = True
                break
            else:
                print("Error: Only 'yes' or 'no' is a valid answer.")
        except ValueError:
            continue
    if do_k_means_for_complementary_data:
        while True:
            try:
                lower_time_simulation_path = input("Please specify the path to the folder containing the "
                                                   "ExpressionData.csv file for the complementary simulation. "
                                                   "Or, type 'cancel' to exit: ")
                lower_time_simulation_inFile = lower_time_simulation_path + "/ExpressionData.csv"
                if lower_time_simulation_path == 'cancel':
                    break
                elif not os.path.exists(lower_time_simulation_inFile):
                    print("Error: No ExpressionData.csv file is present in the specified path to files. Check "
                          "the folder and try again.")
                else:
                    if num_clusters == 1:
                        print("Requested 1 cluster...not performing k-means clustering for 1 cluster.")
                        lower_time_simulation_clusterFile = lower_time_simulation_path + "/ClusterIds.csv"
                        if os.path.exists(lower_time_simulation_clusterFile):
                            print("Deleting the ClusterIds.csv file present.")
                            os.remove(lower_time_simulation_clusterFile)
                    else:
                        complementaryDF = pd.read_csv(lower_time_simulation_inFile, sep=',', index_col=0)
                        cluster_labels = KMeans(n_clusters=int(num_clusters)).fit(complementaryDF.T.values).labels_
                        ClusterIds_df = pd.DataFrame(data=cluster_labels, index=complementaryDF.columns,
                                                     columns=['cl'])
                        write_to_file('ClusterIds_df', 'csv', lower_time_simulation_path, 1)
                        print("The new clusters have been written to the ClusterIds.csv file.")
                    break
            except ValueError:
                continue
